---
title: FOSS For Spectroscopy
author: Bryan A. Hanson, DePauw University
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
---

<!-- Following code to keep printed version cleaner; see https://stackoverflow.com/a/24467913/633251  -->
<style type="text/css" media="print">
a:link:after, a:visited:after {
  content: normal !important;
}
</style>

<!-- See https://kryogenix.org/code/browser/sorttable/ -->
<script src="sorttable.js"></script>

The following table collects information about free and open source software ([FOSS](https://en.wikipedia.org/wiki/Free_and_open-source_software)) for spectroscopy.  All information is taken from the respective websites and/or repositories.  Some softwares have been described in publications.  If so, a link is provided, but keep in mind the document may be behind a paywall.

Unless otherwise noted, the software mentioned here:

* Is suitable for one or more of the following techniques: NMR, IR, Raman, ESR/EPR, fluorescence and UV-Vis.
* Mass *spectrometry* software is not included.
* Software for MRI is not included.

[Stanstrup *et al.*](https://www.mdpi.com/2218-1989/9/10/200) have published a comprehensive paper describing the `R` packages suitable for use in metabolomics, which partially overlaps with the information here.

The [CRAN Task View for Chemometrics & Computational Physics](https://cran.r-project.org/web/views/ChemPhys.html) includes some `R` packages listed here as well as related software.

Additions or corrections?  Please [file an issue](https://github.com/bryanhanson/FOSS4Spectroscopy/issues) with the necessary information or submit a pull request at the [repo](https://github.com/bryanhanson/FOSS4Spectroscopy).

[![Project Status: WIP â€“ Initial development is in progress, but there has not yet been a stable, usable release suitable for the public.](https://www.repostatus.org/badges/latest/wip.svg)](https://www.repostatus.org/#wip)
[![Build Status](https://travis-ci.com/bryanhanson/FOSS4Spectroscopy.svg?branch=master)](https://travis-ci.com/bryanhanson/FOSS4Spectroscopy)


```{r setupR, echo = FALSE, results = "hide"}
# Clean up the workspace but keep the token, if present
keep <- "github_token"
rm(list = ls()[!(ls() %in% keep)])

suppressPackageStartupMessages(library("knitr"))
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("readxl"))
suppressPackageStartupMessages(library("httr"))
suppressPackageStartupMessages(library("lubridate"))
suppressPackageStartupMessages(library("jsonlite"))

opts_chunk$set(echo = FALSE)

source("getGHdates.R") # function to get GH most recent commit dates

# Python library for finding modifed/creation dates
# http://adrien.barbaresi.eu/blog/python-extract-date-web-pages.html
# For the types of sites encountered here, this library does not do
# a great job, so we'll only use it if we have nothing better to try

suppressPackageStartupMessages(library("reticulate"))
py_install("htmldate")

cnt <- 0L # counter for the number of GET calls to Github
```


```{r readDB}
# Please edit FOSS4Spec.xlsx to add information or make corrections.
# Please follow the conventions of existing entries for consistency.
# Remember the table in the web page is sortable so consistency in
# description and notes is especially important for users to obtain
# useful information.

DF <- read_excel("FOSS4Spec.xlsx")
DF <- as.data.frame(DF)
# shorten names for less typing
names(DF) <- c("pkgname", "web", "repo", "pub", "lang", "desc", "notes")
```

```{r universalGHaccess}
# Figure out the build location, and get the needed token
at_home <- FALSE
at_TCI <- FALSE
token_found <- FALSE
token_OK <- FALSE # not used now/yet

# Check to see if we are at TRAVIS-CI
token_value <- Sys.getenv("TRAVIS_CI")
if (token_value != "") {
  token_found <- TRUE
  at_TCI <- TRUE
}

# Check to see if we are on the local/home machine
# This token is generated interactively via "Web Application Flow",
# and is deposited in the local workspace
# See developer.github.com/apps/building-oauth-apps/authorizing-oauth-apps/#web-application-flow
# This token has classes 'Token2.0', 'Token', 'R6' <Token2.0>
if (!at_TCI) {
  token_found <- exists("github_token")
  if (token_found) {
    token_value <- github_token
    at_home <- TRUE
  }
}

# See where we stand and act accordingly
if (!token_found) {
  message("Could not retrieve token - GET calls will be rate-limited by Github")
  # TEMPORARY: just use a few lines for faster testing & not blasting GH limits
  DF <- DF[1:5,]
}
if (token_found) {
  set_config(config(token = token_value)) # applies to all GET requests below
}
```

```{r verifyURLs}
# This takes some time!
ne <- nrow(DF) # number of entries

# Check all URLs, if the site is down handle so table always looks good.
# Site URL might also just be missing from table, handle this too.
webLink <- rep(FALSE, ne) # If TRUE, there is a link in the input table
repoLink <- rep(FALSE, ne)
pubLink <- rep(FALSE, ne)

webOK <- rep(FALSE, ne) # If TRUE, URL was reachable
repoOK <- rep(FALSE, ne)
pubOK <- rep(FALSE, ne)

badWeb <- rep(FALSE, ne) # If TRUE, URL was given but not reachable: report it
badRepo <- rep(FALSE, ne)
badPub <- rep(FALSE, ne)

for (i in 1:ne) {
  if (!is.na(DF$web[i])) {
    # webOK[i] <- identical(status_code(GET(DF$web[i])), 200L)
    webLink[i] <- TRUE
    if (webLink[i] != webOK[i]) badWeb[i] <- TRUE
  }

  if (!is.na(DF$repo[i])) {
    repoOK[i] <- identical(status_code(GET(DF$repo[i])), 200L)
    repoLink[i] <- TRUE
    if (repoLink[i] != repoOK[i]) badRepo[i] <- TRUE
  }

  if (!is.na(DF$pub[i])) {
    pubOK[i] <- identical(status_code(GET(DF$pub[i])), 200L)
    pubLink[i] <- TRUE
    if (pubLink[i] != pubOK[i]) badPub[i] <- TRUE
  }
}
# If URLs are bad they will still be added to the table as hyperlinks, but
# those links will give status 404.
# Write a report so maintainers can check & fix if it's on our end
LinkReport <- data.frame(name = DF$pkgname, webLink, webOK, repoLink, repoOK, pubLink, pubOK, stringsAsFactors = FALSE)
keep <- badPub | badRepo | badWeb
LinkReport <- LinkReport[keep,]
if (nrow(LinkReport) > 0) write.csv(LinkReport, row.names = FALSE, file = "Links404.csv")
```

```{r checkUpdateDate}
# Use the info from checking URLs above
webDate <- as.POSIXct(rep(NA, ne)) # see stackoverflow.com/a/33002710/633251
commitDate <- as.POSIXct(rep(NA, ne))
issueDate <- as.POSIXct(rep(NA, ne))
updateDate <- as.POSIXct(rep(NA, ne))

repoType <- rep("xx", ne)
repoType[grepl("github\\.com", DF$repo)] <- "gh"

for (i in 1:ne) {

  if (webOK[i]) {
    tmp <- system2("wget",
      args = c("-qO-", DF$web[i], "|", "htmldate"),
      stdout = TRUE)
    if (length(tmp) == 1L) webDate[i] <- ymd(tmp)
  }

  if (repoOK[i]) {
    if (repoType[i] == "gh") {
      # NA returned when repo path bad
      tmp <- getGHdates(DF$repo[i], "commits")
      cnt <- cnt + 1
      if (!is.na(tmp)) commitDate[i] <- ymd(tmp)
      tmp <- getGHdates(DF$repo[i], "issues")
      cnt <- cnt + 1
      if (!is.na(tmp)) issueDate[i] <- ymd(tmp)
    }
  }

  # updateDate will be the most recent of webDate, issueDate, commitDate
  updateDate[i] <- max(webDate[i], commitDate[i], issueDate[i], na.rm = TRUE)
}
updateDate <- date(updateDate) # -> ymd

# Write a report
DateReport <- data.frame(name = DF$pkgname, webDate, commitDate, issueDate, updateDate, stringsAsFactors = FALSE)
write.csv(DateReport, row.names = FALSE, file = "DateReport.csv")
```

```{r createNamelink}
# Additional processing of the input values
# Combine name, website and pub as available to create hyperlink
namelink <- DF$pkgname # There must be at least a pkgname in the input table
for (i in 1:ne) {
  if (!is.na(DF$web[i])) {
    namelink[i] <- paste("[", DF$pkgname[i], "](", DF$web[i], ")", sep = "")
  }
  if (!is.na(DF$pub[i])) {
    namelink[i] <- paste(namelink[i], " ([pub](", DF$pub[i], "))", sep = "")
  }
}
```

```{r createTable}
DF2 <- data.frame(namelink, DF$desc, DF$lang, DF$notes, updateDate, stringsAsFactors = FALSE)
names(DF2) <- c("name", "description", "language", "notes", "[status](#status)")
```

<hr>

* *Click on a header to sort the table*
* [Abbreviations](#abbreviations) & terms below the table
* The table currently has `r nrow(DF2)` entries; the majority are `R` (`r length(DF2$language[DF2$language == "R"])`) or `Python` (`r length(DF2$language[DF2$language == "Python"])`).

```{r printTable, results = "asis"}
options(knitr.kable.NA = '')
kable(DF2, table.attr = "class=\"sortable\"") %>%
  kable_styling(c("striped", "bordered", "sortable"))
```
##### Status Column: {#status}

The status column in the table gives the date of the most recent:

* commit to a repository,
* activity on an issue filed in a repository,
* web site update, or
* submission to an archival network such as CRAN

as a proxy for regular maintenance.  Keep in mind that some software is fairly mature and thus an older status date does not necessarily mean the software is not maintained.  Follow the links to the websites for more details.

**The date is found by automatic checking of sites with valid links.  Commits and issues are only checked for Github sites. Web site updates are found using the `Python` package [htmldate](https://pypi.org/project/htmldate/.)**

##### Abbreviations & Terms: {#abbreviations}

* __CRAN:__ [Comprehensive R Archival Network](https://cran.r-project.org/)
* __EDA:__ Exploratory data analysis (unsupervised chemometrics)
* __language:__ Most software is built on several languages. In the table, "language" refers to the language one uses to interact with the software. Some software has partial or complete interactive features.
* __nD NMR:__ n-dimensional NMR, 1D, 2D, 3D etc
* __Python:__ Multipurpose programming language [details](https://www.python.org/about/)
* __R:__ A software environment for statistical computing and graphics [details, platforms](https://www.r-project.org/)
* __VM:__ Virtual machine.  Any of several means of delivering software to run on any computer, such as VirtualBox or Docker containers.
